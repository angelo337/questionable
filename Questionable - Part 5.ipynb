{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for Paperspace. Manage these via conda or pipenv on your own machine\n",
    "!pip --quiet install nmslib flask torch transformers sklearn pyarrow seaborn spacy[cuda92] torchtext\n",
    "%run init_container.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import random\n",
    "import pickle\n",
    "from itertools import islice\n",
    "import multiprocessing as mp\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import sklearn\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.strings import hash_string\n",
    "from unidecode import unidecode\n",
    "\n",
    "import nmslib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from itertools import islice\n",
    "from torchtext.data import Field, Dataset, BucketIterator, Example, RawField\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from transformers import *\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qa.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spacy.prefer_gpu()\n",
    "spen = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a while the first time, since from_pretrained() downloads and caches the model weights\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForQuestionAnswering \\\n",
    "    .from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad') \\\n",
    "    .to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SQUAD_TRAIN) as f:\n",
    "    doc = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = []\n",
    "questions = []\n",
    "topics = []\n",
    "for topic in doc[\"data\"]:\n",
    "    topics.append(topic[\"title\"])\n",
    "    for pgraph in topic[\"paragraphs\"]:\n",
    "        paragraphs.append(pgraph[\"context\"])\n",
    "        for qa in pgraph[\"qas\"]:\n",
    "            if not qa[\"is_impossible\"]:\n",
    "                questions.append(qa[\"question\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = random.choice(doc[\"data\"])\n",
    "paragraph = random.choice(topic[\"paragraphs\"])\n",
    "question = random.choice(paragraph[\"qas\"])\n",
    "topic[\"title\"], question[\"question\"], paragraph[\"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paragraphs), len(questions), random.sample(paragraphs, 2), random.sample(questions, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\", \".join(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if os.path.isfile(DOCBIN_CACHE) and os.path.isdir(VOCAB_CACHE):\n",
    "    spen.vocab.from_disk(VOCAB_CACHE)\n",
    "\n",
    "    with open(DOCBIN_CACHE, \"rb\") as f:\n",
    "        bb = f.read()\n",
    "        doc_bin = DocBin().from_bytes(bb)\n",
    "    docs = list(doc_bin.get_docs(spen.vocab))\n",
    "else:\n",
    "    doc_bin = DocBin(attrs=[\"LEMMA\", \"ENT_IOB\", \"ENT_TYPE\"], store_user_data=True)\n",
    "    for doc in spen.pipe(tqdm(paragraphs)):\n",
    "        doc_bin.add(doc)\n",
    "    with open(DOCBIN_CACHE, \"wb\") as f:\n",
    "        f.write(doc_bin.to_bytes())\n",
    "    spen.vocab.to_disk(VOCAB_CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def lemmatize_preproc(doc):\n",
    "    return [unidecode(tok.lemma_.lower()) for tok in doc if not tok.is_stop]\n",
    "\n",
    "if not os.path.isfile(VECTOR_CACHE):\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        analyzer=lemmatize_preproc,\n",
    "        stop_words='english', min_df=10, max_df=.5, ngram_range=(1,3))\n",
    "    tfidf = vectorizer.fit_transform(docs)\n",
    "    with open(VECTOR_CACHE, \"wb\") as f:\n",
    "        pickle.dump(dict(vectorizer=vectorizer, tfidf=tfidf), f)\n",
    "else:\n",
    "    with open(VECTOR_CACHE, \"rb\") as f:\n",
    "        cache = pickle.load(f)\n",
    "        tfidf = cache[\"tfidf\"]\n",
    "        vectorizer = cache[\"vectorizer\"]\n",
    "        \n",
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabSTOI:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tok = tokenizer\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        return self.tok.convert_tokens_to_ids([key])[0]\n",
    "    \n",
    "class VocabITOS:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tok = tokenizer\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        return self.tok.convert_ids_to_tokens([key])[0]\n",
    "    \n",
    "class BertVocab:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.itos = VocabITOS(tokenizer)\n",
    "        self.stoi = VocabSTOI(tokenizer)\n",
    "def ident(x):\n",
    "    return x\n",
    "\n",
    "def default_preproc(s):\n",
    "    #print(f'input type {type(s)} value: {s}')\n",
    "    return [\"[CLS]\"] + tokenizer.tokenize(s)[:510] + [\"[SEP]\"]\n",
    "\n",
    "class SpacyBertField(Field):\n",
    "    \"\"\"Transforms spaCy documents into Bert token lists\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocab=BertVocab(tokenizer),\n",
    "                 preprocessing=default_preproc,\n",
    "                 **kwargs):\n",
    "        super().__init__(\n",
    "            pad_token=tokenizer.pad_token,\n",
    "            preprocessing=preprocessing,\n",
    "            tokenize=ident,\n",
    "            batch_first=True,\n",
    "            **kwargs)\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def build_vocab(self, *args, **kw):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDUCTION_DIMS = 1024\n",
    "def reduce_embeds(toks, emb):\n",
    "    N = (toks != 0).sum(axis = 1, keepdim=True)\n",
    "    sumq = emb.sum(axis=1)\n",
    "    meanq = sumq / N\n",
    "    maxq, _ = emb.max(axis=1)\n",
    "    minq, _ = emb.min(axis=1)\n",
    "    #return torch.cat([meanq, minq, maxq], axis=1)\n",
    "    return maxq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [' '.join([tok.lemma_ for tok in doc if not tok.is_stop]) for doc in tqdm(docs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fields = [('index', RawField()), ('context', SpacyBertField())]\n",
    "\n",
    "def examplify(args):\n",
    "    (i, doc) = args\n",
    "    return Example.fromlist([i, doc], fields)\n",
    "\n",
    "with mp.Pool() as pool:\n",
    "    examples = pool.map(examplify, enumerate(tqdm(texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(examples, fields)\n",
    "buckets = BucketIterator(dataset=ds,\n",
    "                         batch_size=24,\n",
    "                         device=device,\n",
    "                         shuffle=False,\n",
    "                         sort=True,\n",
    "                         sort_key=lambda ex: -len(ex.context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = np.zeros((len(texts), REDUCTION_DIMS), dtype=np.float32)\n",
    "for b in tqdm(buckets):\n",
    "    with torch.no_grad():\n",
    "        output = model.bert.embeddings(b.context)\n",
    "        embeds[b.index] = reduce_embeds(b.context, output).cpu()\n",
    "\n",
    "# Either I messed up or z-normalization completely destroys the embedding\n",
    "# Accuracy went from 60% to 2%.\n",
    "# Just subtracting mean accounts for most of this drop.\n",
    "# Should try PCA whitening instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds.min(), embeds.max(), embeds.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(embeds > 10).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sentence(query):\n",
    "    if type(query) is str:\n",
    "        query = spen(query)\n",
    "    query = ' '.join([word.lemma_ for word in query if not word.is_stop])\n",
    "    query_ids = tokenizer.encode(\"[CLS] \" + query + \" [SEP]\", add_special_tokens=False, max_length=512)\n",
    "    X = torch.tensor(query_ids, device=device).unsqueeze(0)\n",
    "    query_emb = model.bert.embeddings(X)\n",
    "    result = reduce_embeds(X, query_emb).cpu().numpy()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    foo = embed_sentence(\"how now brown cow\")\n",
    "foo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "index = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "index.addDataPointBatch(embeds)\n",
    "index.createIndex({'post': 2, 'efConstruction': 500, 'M': 64}, print_progress=True)\n",
    "index.setQueryTimeParams(dict(ef=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bfidx = nmslib.init(method='brute_force', space='cosinesimil')\n",
    "bfidx.addDataPointBatch(embeds)\n",
    "bfidx.createIndex(print_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.knnQuery(embeds[3000], k=30), bfidx.knnQuery(embeds[3000], k=30), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    query = embed_sentence(\"What are common pieces of computers?\")\n",
    "    results, dists = bfidx.knnQuery(query, k=50)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i,docs[i].text) for i in results[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_embed_trial(k=20):\n",
    "    topic = random.choice(doc[\"data\"])\n",
    "    paragraph = random.choice(topic[\"paragraphs\"])\n",
    "    question = random.choice(paragraph[\"qas\"])\n",
    "    with torch.no_grad():\n",
    "        query = embed_sentence(question[\"question\"])\n",
    "        results, dists = index.knnQuery(query, k=k)\n",
    "    return paragraph[\"context\"] in [docs[i].text for i in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = 0\n",
    "for i in tqdm(range(1000)):\n",
    "    hits += knn_embed_trial(25)\n",
    "\n",
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brute_embed_trial(k=20):\n",
    "    topic = random.choice(doc[\"data\"])\n",
    "    paragraph = random.choice(topic[\"paragraphs\"])\n",
    "    question = random.choice(paragraph[\"qas\"])\n",
    "    with torch.no_grad():\n",
    "        query = embed_sentence(question[\"question\"])\n",
    "        results, dists = bfidx.knnQuery(query, k=k)\n",
    "    return paragraph[\"context\"] in [docs[i].text for i in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = 0\n",
    "for i in tqdm(range(1000)):\n",
    "    hits += brute_embed_trial(25)\n",
    "\n",
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brute_tfidf_trial(k=20):\n",
    "    topic = random.choice(doc[\"data\"])\n",
    "    paragraph = random.choice(topic[\"paragraphs\"])\n",
    "    question = random.choice(paragraph[\"qas\"])[\"question\"]\n",
    "    query = vectorizer.transform([spen(question)])\n",
    "    scores = (tfidf * query.T).toarray()\n",
    "    results = (np.flip(np.argsort(scores, axis=0)))\n",
    "    return paragraph[\"context\"] in [docs[i].text for i in results[:k, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = 0\n",
    "for i in tqdm(range(1000)):\n",
    "    hits += brute_tfidf_trial(50)\n",
    "\n",
    "hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICS = set([\"DATE\", \"TIME\", \"PERCENT\", \"MONEY\", \"QUANTITY\", \"ORDINAL\", \"CARDINAL\"])\n",
    "def doc_entities(doc):\n",
    "    ents = [e for e in doc.ents if e.label_ not in NUMERICS]\n",
    "    result = (unidecode(w.lemma_.lower()) for s in ents for w in s if w.is_alpha and not w.is_stop)\n",
    "    #return list(result)\n",
    "    return [w for w in result if w not in vectorizer.vocabulary_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ent_vecr = CountVectorizer(\n",
    "    analyzer=doc_entities,\n",
    "    stop_words='english', max_df=10)\n",
    "ent_tfidf = ent_vecr.fit_transform(docs)\n",
    "\n",
    "N = 10_001\n",
    "hashed_ents = [set() for i in range(N)]\n",
    "for (i, words) in enumerate(tqdm(ent_vecr.inverse_transform(ent_tfidf))):\n",
    "    for w in words:\n",
    "        h = hash_string(str(w))\n",
    "        hashed_ents[h%N].add(i)\n",
    "len(ent_vecr.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contexts_by_entities(doc):\n",
    "    \"\"\"Returns a set of document ids that *might* be related to named entities in the pre-processed question\"\"\"\n",
    "    ents = doc_entities(doc)\n",
    "    buckets = [hash_string(word)%N for word in ents]\n",
    "    return set([doc_id for slot in buckets for doc_id in hashed_ents[slot]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_trial(k=20):\n",
    "    rs = set()\n",
    "    topic = random.choice(doc[\"data\"])\n",
    "    paragraph = random.choice(topic[\"paragraphs\"])\n",
    "    qa = random.choice(paragraph[\"qas\"])\n",
    "    question = qa[\"question\"]\n",
    "    \n",
    "    query = vectorizer.transform([spen(question)])\n",
    "    scores = (tfidf * query.T).toarray()\n",
    "    results = (np.flip(np.argsort(scores, axis=0)))\n",
    "    rs.update(results[:k, 0].tolist())\n",
    "    \n",
    "    if paragraph[\"context\"] in [docs[i].text for i in results[:k, 0]]:\n",
    "        return True\n",
    "\n",
    "    with torch.no_grad():\n",
    "        query = embed_sentence(question)\n",
    "        results, dists = bfidx.knnQuery(query, k=k)\n",
    "    rs.update(results)\n",
    "        \n",
    "    if paragraph[\"context\"] in [docs[i].text for i in results]:\n",
    "        return True\n",
    "    \n",
    "    results = contexts_by_entities(spen(question))\n",
    "    rs.update(results)\n",
    "    \n",
    "    if paragraph[\"context\"] in [docs[i].text for i in results]:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = 0\n",
    "for i in tqdm(range(1000)):\n",
    "    hits += combined_trial(50)\n",
    "\n",
    "hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All together now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_contexts(question, k=20):\n",
    "    preproc = spen(question)\n",
    "\n",
    "    query = vectorizer.transform([preproc])\n",
    "    scores = (tfidf * query.T).toarray()\n",
    "    results = (np.flip(np.argsort(scores, axis=0)))\n",
    "    tagged = { i: \"TFIDF\" for i in results[:k, 0].tolist() }\n",
    "    rs = set(tagged.keys())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        query = embed_sentence(preproc)\n",
    "        results, dists = bfidx.knnQuery(query, k=k)\n",
    "        embed_set = set(results)\n",
    "\n",
    "    #tagged.update({ i: \"EMBED\" for i in embed_set.difference(rs)})\n",
    "    tagged.update({ i: \"EMBED\" for i in embed_set})\n",
    "    rs.update(results)\n",
    "    tagged\n",
    "\n",
    "    entity_set = set(contexts_by_entities(preproc))\n",
    "    #tagged.update({ i: \"ENTITY\" for i in entity_set.difference(rs)})\n",
    "    tagged.update({ i: \"ENTITY\" for i in entity_set})\n",
    "\n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = random.choice(doc[\"data\"])\n",
    "paragraph = random.choice(topic[\"paragraphs\"])\n",
    "qa = random.choice(paragraph[\"qas\"])\n",
    "question = qa[\"question\"]\n",
    "topic[\"title\"], question, qa[\"is_impossible\"],  paragraph[\"context\"], qa[\"answers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question = \"What did humans hunt during the Paleolithic?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "contexts = combined_contexts(question, 50)\n",
    "question_df = pd.DataFrame.from_records([ {\n",
    "    'question': question,\n",
    "    'context':  docs[i].text,\n",
    "    'tag': tag\n",
    "} for (i, tag) in contexts.items() ])\n",
    "question_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_df[\"doc_id\"] = contexts\n",
    "question_df[\"encoded\"] = question_df.apply(lambda row: tokenizer.encode(\"[CLS] \" + row[\"question\"] + \" [SEP] \" + row[\"context\"] + \" [SEP]\", add_special_tokens=False, max_length=512), axis=1)\n",
    "question_df[\"tok_type\"] = question_df.apply(lambda row: [0 if i <= row[\"encoded\"].index(102) else 1 for i in range(len(row[\"encoded\"]))], axis=1)\n",
    "question_df[\"context_start\"] = question_df.apply(lambda row: row[\"encoded\"].index(102) + 1, axis=1)\n",
    "question_df[\"context_end\"] = question_df.apply(lambda row: len(row[\"encoded\"])-1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO batching and ranking contexts by jaccard index of character-level n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chargram = TfidfVectorizer(analyzer='char_wb', ngram_range=(3,3))\n",
    "foo = chargram.fit_transform(question_df.context)\n",
    "bar = chargram.transform([question])\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_LIMIT = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chargram.inverse_transform(bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = np.flip(np.asarray((foo * bar.transpose()).todense()).squeeze().argsort().astype(np.int))[:INFER_LIMIT]\n",
    "question_df = question_df.iloc[rows.tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    X = torch.nn.utils.rnn.pad_sequence([torch.tensor(row) for row in question_df[\"encoded\"]], batch_first=True).to(device)\n",
    "    T = torch.nn.utils.rnn.pad_sequence([torch.tensor(row) for row in question_df[\"tok_type\"]], batch_first=True).to(device)\n",
    "    start_scores, end_scores = model(X, token_type_ids=T)\n",
    "    max_score, max_start = torch.max(start_scores, axis=1)\n",
    "    soft_max = F.softmax(max_score, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_max.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_answer(row):\n",
    "    input_ids = row.encoded\n",
    "    offset = row.answer_start\n",
    "    length = np.clip(row.answer_length, 0, 20)\n",
    "    return tokenizer.decode(input_ids[offset:][:length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_df = question_df[[\"doc_id\", \"tag\", \"context\", \"encoded\", \"context_start\", \"context_end\"]].copy()\n",
    "answer_df[\"answer_score\"] = max_score.cpu().numpy()\n",
    "answer_df[\"answer_start\"] = max_start.cpu().numpy()\n",
    "answer_df[\"answer_softmax\"] = soft_max.cpu().numpy()\n",
    "max_len = torch.zeros_like(max_start)\n",
    "for i in range(max_start.shape[0]):\n",
    "    max_len[i] = torch.argmax(end_scores[i,max_start[i]:]) + 1\n",
    "answer_df[\"answer_length\"] = max_len.cpu().numpy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_df = answer_df[answer_df.answer_start >= answer_df.context_start]\n",
    "answer_df = answer_df[answer_df.answer_start <= answer_df.context_end]\n",
    "answer_df = answer_df[answer_df.answer_softmax >= 1.0 / INFER_LIMIT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_df = answer_df.sort_values(by=\"answer_score\", ascending=False)\n",
    "answer_df[\"answer\"] = answer_df.apply(decode_answer, axis=1) if len(answer_df.index) > 0 else \"\"\n",
    "answer_df[[\"answer_softmax\", \"answer_score\", \"answer\"]].head()\n",
    "answer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_df[[\"answer_softmax\", \"answer_score\", \"answer\", \"doc_id\", \"tag\", \"context\"]].iloc[:5].to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
